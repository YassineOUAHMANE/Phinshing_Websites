# Phishing Detection System

## üìã Vue d'ensemble

Ce projet d√©veloppe un **syst√®me de d√©tection automatis√© de sites de phishing** utilisant le machine learning. L'approche combine l'**extraction de features brutes**, l'**analyse statistique rigoureuse**, et la **s√©lection automatique de features** pour construire un mod√®le pr√©dictif robuste et interpr√©table.

### Objectifs Principaux
- Classifier les URLs comme **l√©gitimes (b√©nignes)** ou **malveillantes (phishing)**
- Justifier chaque d√©cision par une **analyse statistique des donn√©es**
- Cr√©er des **features interpr√©tables** bas√©es sur des insights m√©tier
- Atteindre une **performance optimale** avec un ensemble minimal de features

---

## üîç M√©thodologie

### 1Ô∏è‚É£ Extraction des Features BRUTES
Le projet extrait des features **sans cat√©gorisation a priori** :

**Features URL**
- Longueur URL, domaine, FQDN
- Entropie du domaine (caract√®res al√©atoires)
- Rapport consonnes/voyelles
- Pr√©sence d'IP, tirets, symboles '@'
- Profondeur de sous-domaines

**Features DNS**
- Compteurs : NS, MX, TXT, SOA, A, AAAA
- Pr√©sence de DMARC
- Code pays (GeoIP)
- Code ASN

**Features SSL/TLS**
- Validit√© du certificat
- √âmetteur du certificat (brut)
- Dur√©e de validit√©
- Wildcard (*.domaine.com)

**Features Contenu**
- Nombre de ressources externes
- Nombre de domaines uniques
- Statut HTTP
- Redirections
- Nombre de cookies
- Technologies d√©tect√©es

**Features Historique**
- Pr√©sence dans Wayback Machine
- √Çge du domaine
- Ann√©es actives d'historique

### 2Ô∏è‚É£ Analyse Statistique des Donn√©es
Plut√¥t que d'imposer des r√®gles arbitraires, on **analyse le dataset** pour identifier ce qui distingue vraiment les phishings :

#### Test Chi-2 pour chaque cat√©gorie
```
Hypoth√®se : La distribution d'une feature est-elle significativement 
diff√©rente entre domaines b√©nins et malveillants ?
‚Üí p-value < 0.05 = significatif statistiquement
```

#### Identification des TLDs risqu√©s
- Calcul du **ratio malveillant** = malveillants / total pour chaque TLD
- Comparaison au **baseline global** (baseline √ó 1.2 = seuil)
- S√©lection : ratio_malicious > baseline √ó 1.2 ET p-value < 0.05

**Exemple concret** :
- Baseline global : 60% malveillants
- Seuil : 60% √ó 1.2 = 72%
- TLD ".tk" : 85% ‚Üí  S√©lectionn√© (haut risque)
- TLD ".com" : 62% ‚Üí  Pas s√©lectionn√© (trop proche du normal)

#### Analyse des √©metteurs SSL
- Identifie les √©metteurs **√† haut risque** (ratio > baseline √ó 1.2)
- Identifie les √©metteurs **premium** (ratio < baseline √ó 0.5)
- Justifie chaque cat√©gorisation par des statistiques

### 3Ô∏è‚É£ Feature Engineering Justifi√© par les Donn√©es

#### Cat√©gories bas√©es sur l'analyse statistique
```python
is_high_risk_tld      # TLDs significativement plus risqu√©s
is_high_risk_ssl      # √âmetteurs SSL non-fiables
is_premium_ssl        # √âmetteurs SSL r√©put√©s
is_high_risk_country  # Pays avec taux de phishing √©lev√©
ssl_is_short_validity # Certificats √† courte dur√©e
```

#### Scores composites

**DNS Trust Score** (0-17)
```
= clip(dns_ns_count, 0, 5) 
  + clip(dns_mx_count, 0, 5) 
  + clip(dns_txt_count, 0, 5) 
  + dmarc_exists √ó 2
```
- **Logique** : Domains l√©gitimes = infrastructure DNS solide
- **Clip** : √âvite que 100 serveurs NS noient le score
- **DMARC** : Double poids (important pour la s√©curit√© email)

**Domain Maturity Score** (0-‚àû)
```
= log1p(domain_age_days) 
  + wayback_years_active √ó 0.5 
  + has_wayback_history √ó 3
```
- **Logique** : Les domaines anciens sont plus l√©gitime
- **log1p** : √âvite log(0) et compresse les valeurs extr√™mes
- **Exemple** : 0 jours ‚Üí 0, 365 jours ‚Üí 5.9, 10000 jours ‚Üí 9.2

**URL Suspicion Score** (0-‚àû)
```
= domain_entropy 
  + domain_cv_ratio √ó 0.2 
  + subdomain_depth 
  + is_high_risk_tld √ó 2 
  + has_ip_in_url √ó 5 
  + url_at_count √ó 3
```
- **Logique** : D√©tecte les URLs suspectes
- **IP dans URL** : Poids fort (tr√®s phishing)
- **Symbole @** : Poids fort (obfuscation classique)

**SSL Trust Score** (0-5)
```
= ssl_is_valid 
  + is_premium_ssl √ó 2 
  + (1 - is_high_risk_ssl) 
  + ssl_is_wildcard 
  + (1 - ssl_is_short_validity)
```
- **Logique** : Mesure la confiance du certificat SSL
- **Premium SSL** : Double poids (LetsEncrypt, DigiCert = fiable)

**Legitimacy Score** (combin√©)
```
= dns_trust_score 
  + ssl_trust_score 
  + domain_maturity_score 
  - url_suspicion_score
```

#### Interactions (XOR features)
```python
entropy_x_no_history     # Domaine al√©atoire SANS historique = tr√®s suspect
risky_tld_x_risky_ssl    # TLD risqu√© + SSL louche = cumul de risques
short_ssl_x_no_history   # Certificat court + pas d'historique = phishing
```

### 4Ô∏è‚É£ Forward Selection (S√©lection Automatique)
Plut√¥t que de garder toutes les features, on s√©lectionne **it√©rativement** :

**Algorithme**
1. Commencer avec 0 features
2. Pour chaque feature restante : tester en validation crois√©e (5-fold)
3. Ajouter la feature qui am√©liore le score ROC-AUC le plus
4. Arr√™ter si am√©lioration < 0.0005 pendant 3 it√©rations
5. R√©sultat : ~15-20 features pertinentes sur 60+

**Avantages**
- √âlimine la redondance
- R√©duit l'overfitting
- Am√©liore la g√©n√©ralisation
- Facilite l'interpr√©tation

### 5Ô∏è‚É£ Mod√©lisation et √âvaluation

**Mod√®les test√©s**
- Logistic Regression (baseline simple)
- Random Forest (robuste aux outliers)
- Gradient Boosting (flexible)
- LightGBM (rapide et efficace)
- XGBoost (√©tat de l'art)

**M√©triques**
- **ROC-AUC** : Mesure la discrimination entre classes
- **Accuracy** : % de pr√©dictions correctes
- **Precision** : % de phishings d√©tect√©s sont vraiment des phishings
- **Recall** : % des vrais phishings d√©tect√©s
- **F1-Score** : Harmonie precision-recall
- **PR-AUC** : Robuste au d√©s√©quilibre des classes

---

## üìä Analyse Statistique Cl√©

### Approche M√©diane pour SSL Validity
```python
benign_median = 365 jours    # Certificats d'un an typiques
malicious_median = 180 jours # Certificats temporaires
seuil = (365 + 180) / 2 = 272.5 jours
```

**Pourquoi la m√©diane ?**
- Insensible aux outliers (certificats de 10 ans)
- Plus repr√©sentative que la moyenne
- M√©diane de deux classes = point d'√©quilibre optimal

### Filtrage par Multiplicateurs
```
TLD √† haut risque     : ratio_malicious > baseline √ó 1.2  (20% au-dessus)
SSL Premium           : ratio_malicious < baseline √ó 0.5  (50% en-dessous)
```

**Justification**
- Sans multiplicateur : trop de faux positifs
- √ó 1.2 : Capture les vraies anomalies
- √ó 0.5 : Identifie les certificats premium (LetsEncrypt, etc.)

---

## üóÇÔ∏è Structure du Projet

```
Project_Phishing/
‚îú‚îÄ‚îÄ phishing_detection.ipynb   # Notebook principal
‚îú‚îÄ‚îÄ README.md                  # Documentation
```

### Format JSON des donn√©es
```json
{
  "url": "https://example.com",
  "metadata": {
    "rd": "example",
    "fqdn": "example.com",
    "tld": "com"
  },
  "host_info": {
    "ns": {"answers": [...]},
    "mx": {"answers": [...]},
    "txt": {"answers": [...]},
    "ssl": {
      "is_valid_cert": true,
      "issuer": "Let's Encrypt",
      "valid_from": "2024-01-01",
      "valid_until": "2025-01-01"
    },
    "maxmind": [{"answers": {"cc_code": "US"}}]
  },
  "content_info": {
    "status_code": 200,
    "title": "Example Domain",
    "har": [...]
  },
  "additional": {
    "rd": {
      "wayback_info": {
        "first_ts": "20150101",
        "years": {}
      }
    }
  }
}
```

---

## üöÄ Utilisation

### 1. Installation des d√©pendances
```bash
pip install pandas numpy scikit-learn matplotlib seaborn \
            tqdm lightgbm xgboost scipy
```

### 2. Pr√©paration des donn√©es
```python
# Placer les fichiers JSON dans :
# - Benign_Data_BDA/    (domaines l√©gitimes)
# - Final_Phishing_Dataset/  (domaines malveillants)
```

### 3. Ex√©cution du pipeline
```python
# Extraction brute
extractor = RawFeatureExtractor()
df = load_and_extract(all_files, label, extractor)

# Analyse statistique
tld_analysis = analyze_categorical_feature(df, 'tld_raw')
ssl_analysis = analyze_categorical_feature(df, 'ssl_issuer_raw')

# Feature engineering
df_engineered = create_data_driven_features(df, tld_analysis, ssl_analysis)

# Forward selection
forward_selector.fit(X_train, y_train)

# Mod√©lisation
best_model.fit(X_train_selected, y_train)
```

### 4. Pr√©diction sur nouveau domaine
```python
# Extraire features
new_features = extractor.extract_all_features(data)
new_features_engineered = create_data_driven_features(pd.DataFrame([new_features]))
X_new_selected = new_features_engineered[selected_features]

# Pr√©dire
prediction = best_model.predict(X_new_selected)
probability = best_model.predict_proba(X_new_selected)[0, 1]

print(f"Phishing Probability: {probability:.2%}")
```

---

## üìà R√©sultats Attendus

**Performance typique** (validation crois√©e 5-fold) :
- ROC-AUC : 0.95+
- Accuracy : 92-95%
- Precision : 90-94%
- Recall : 90-95%
- F1-Score : 0.92+

**Features les plus importants** (selon Random Forest) :
1. Domain maturity score
2. SSL trust score
3. Domain entropy
4. URL suspicion score
5. Has wayback history
6. DNS trust score
7. TLD risk index
8. SSL validity days

---

## üîë Points Cl√©s de la Conception

### Approche Bas√©e sur les Donn√©es
- **Pas d'hypoth√®ses arbitraires** : Tout est justifi√© par l'analyse statistique
- **Chi-2 test** : Validation formelle de la significativit√©
- **Multiplicateurs adaptatifs** : Thresholds bas√©s sur le baseline

### Robustesse
- **Clip() sur les features** : √âvite la domination des outliers
- **log1p() pour les √¢ges** : Transformation stable
- **M√©diane au lieu de moyenne** : R√©sistant aux valeurs extr√™mes
- **Forward selection** : √âlimine la redondance

### Interpr√©tabilit√©
- **Features composites explicites** : dns_trust_score, legitimacy_score
- **Scores m√©tier clairs** : Ce qu'ils mesurent est compr√©hensible
- **Interactions logiques** : entropy_x_no_history a un sens

### G√©n√©ralisation
- **Validation crois√©e 5-fold** : Validation robuste
- **Stratification** : √âquilibre train/test
- **StandardScaler** : Normalisation des features

---

## üìö Concepts Expliqu√©s

### Pourquoi `clip(0, 5)` ?
Sans limites, un domaine avec 100 serveurs NS dominerait le score. Avec `clip(0, 5)`, on cr√©e une saturation √† 5, √©vitant la distorsion.

### Pourquoi `log1p()` ?
- `log(0)` ‚Üí erreur
- `log1p(0)` ‚Üí 0
- Compresse les grandes valeurs sans perdre les petites diff√©rences

### Pourquoi `baseline √ó 1.2` ?
Point de s√©v√©rit√© objectif : s√©lectionner **seulement** ce qui est 20% au-dessus du normal, √©vitant les borderline.

### Pourquoi Forward Selection ?
Avec 60+ features, 90% seraient redondantes. Forward selection garde **seulement les 15-20 vraiment utiles**, am√©liorant la g√©n√©ralisation.

---

## üîó R√©f√©rences

- **Chi-2 Test** : Test d'ind√©pendance statistique ([Wikipedia](https://en.wikipedia.org/wiki/Chi-squared_test))
- **Forward Feature Selection** : Technique de s√©lection it√©rative ([Scikit-Learn](https://scikit-learn.org/))
- **ROC-AUC** : M√©trique de performance ([Understanding ROC Curves](https://en.wikipedia.org/wiki/Receiver_operating_characteristic))
- **Phishing Detection Literature** : Domain-based features are proven discriminative

---

## üë§ Auteur
Yassine - Projet de d√©tection de phishing bas√© sur l'analyse statistique
